{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "eP9VcOVoebew"
      },
      "source": [
        "# OpenCV fundamentals\n",
        "\n",
        "This notebook covers opening files, looking at pixels, and some simple image processing techniques.\n",
        "\n",
        "We'll use the following sample image, stolen from the Internet. But you can use whatever image you like.\n",
        "\n",
        "![No idea](https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/noidea.jpg \"I have no idea\")\n",
        "\n",
        "<p>\n",
        " Estimated time needed: <strong>20 min</strong>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-jEyTpSTebff"
      },
      "source": [
        "Taken from: [GitHub](https://github.com/computationalcore/introduction-to-opencv/blob/master/notebooks/1-Fundamentals.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "cIU7W8Wmebey"
      },
      "source": [
        "## Python getting started\n",
        "\n",
        "First we need to import the relevant libraries: OpenCV itself, Numpy, and a couple of others. Common and Video are simple data handling and opening routines that you can find in the OpenCV Python Samples directory or from the github repo linked above.  We'll start each notebook with the same includes - you don't need all of them every time (so this is bad form, really) but it's easier to just copy and paste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "TXKxw8iJebez"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download the test image and utils files\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/noidea.jpg \\\n",
        "    -O noidea.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/utils/common.py \\\n",
        "    -O common.py\n",
        "\n",
        "# These imports let you use opencv\n",
        "import cv2 #opencv itself\n",
        "import common #some useful opencv functions\n",
        "import numpy as np # matrix manipulations\n",
        "\n",
        "# The following are to do with this interactive notebook code\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
        "import pylab # this allows you to control figure size \n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "htK6mm-Gebe2"
      },
      "source": [
        "Now we can open an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "Ah762ATHebe3"
      },
      "outputs": [],
      "source": [
        "input_image=cv2.imread('noidea.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "ut1_Lwdgebe5"
      },
      "source": [
        "We can find out various things about that image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "awdTYn4Gebe6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(input_image.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "af7iQyhqebe8"
      },
      "outputs": [],
      "source": [
        "print(input_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "UhxrodZrebe_"
      },
      "outputs": [],
      "source": [
        "print(input_image.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "stSDqhuBebfA"
      },
      "source": [
        "**gotcha** that last one (datatype) is one of the tricky things about working in Python. As it's not strongly typed, Python will allow you to have arrays of different types but the same size, and some functions will return arrays of types that you probably don't want. Being able to check and inspect the datatype like this is very useful and is one of the things I often find myself doing in debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "woP9RhyCebfB"
      },
      "outputs": [],
      "source": [
        "plt.imshow(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "6VFxWhvUebfD"
      },
      "source": [
        "What this illustrates is something key about OpenCV: it doesn't store images in RGB format, but in BGR format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "zgEQX0isebfD"
      },
      "outputs": [],
      "source": [
        "# split channels\n",
        "b,g,r=cv2.split(input_image)\n",
        "# show one of the channels (this is red - see that the sky is kind of dark. try changing it to b)\n",
        "plt.imshow(r, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "XqE1jCKaebfG"
      },
      "source": [
        "## converting between colour spaces, merging and splitting channels\n",
        "\n",
        "We can convert between various colourspaces in OpenCV easily. We've seen how to split, above. We can also merge channels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "Ev_3hJKLebfH"
      },
      "outputs": [],
      "source": [
        "merged=cv2.merge([r,g,b])\n",
        "# merge takes an array of single channel matrices\n",
        "plt.imshow(merged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "cJ-UCAynebfJ"
      },
      "source": [
        "OpenCV also has a function specifically for dealing with image colorspaces, so rather than split and merge channels by hand you can use this instead. It is usually marginally faster...\n",
        "\n",
        "There are something like 250 color related flags in OpenCV for conversion and display. The ones you are most likely to use are COLOR_BGR2RGB for RGB conversion, COLOR_BGR2GRAY for conversion to greyscale, and COLOR_BGR2HSV for conversion to Hue,Saturation,Value colour space. [http://docs.opencv.org/trunk/de/d25/imgproc_color_conversions.html] has more information on how these colour conversions are done. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "egPmVUvYebfK"
      },
      "outputs": [],
      "source": [
        "COLORflags = [flag for flag in dir(cv2) if flag.startswith('COLOR') ]\n",
        "print(len(COLORflags))\n",
        "\n",
        "# If you want to see them all, rather than just a count uncomment the following line\n",
        "#print(COLORflags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "INRZEZdvebfM"
      },
      "outputs": [],
      "source": [
        "opencv_merged=cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(opencv_merged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "lfo1Lue9ebfN"
      },
      "source": [
        "## Getting image data and setting image data\n",
        "\n",
        "Images in python OpenCV are numpy arrays. Numpy arrays are optimised for fast array operations and so there are usually fast methods for doing array calculations which don't actually involve writing all the detail yourself. So it's usually bad practice to access individual pixels, but you can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "32AQVQ0uebfO"
      },
      "outputs": [],
      "source": [
        "pixel = input_image[100,100]\n",
        "print(pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "OE1vlYo2ebfQ"
      },
      "outputs": [],
      "source": [
        "input_image[100,100] = [0,0,0]\n",
        "pixelnew = input_image[100,100]\n",
        "print(pixelnew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "KsFd9SBzebfS"
      },
      "source": [
        "## Getting and setting regions of an image\n",
        "\n",
        "In the same way as we can get or set individual pixels, we can get or set regions of an image. This is a particularly useful way to get a region of interest to work on. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "D0rwsf8sebfS"
      },
      "outputs": [],
      "source": [
        "dogface = input_image[60:250, 70:350]\n",
        "plt.imshow(dogface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "i1xm1L5MebfU"
      },
      "outputs": [],
      "source": [
        "fresh_image=cv2.imread('noidea.jpg') # it's either start with a fresh read of the image, \n",
        "                                  # or end up with dogfaces on dogfaces on dogfaces \n",
        "                                   # as you re-run parts of the notebook but not others... \n",
        "                            \n",
        "fresh_image[200:200+dogface.shape[0], 200:200+dogface.shape[1]]=dogface\n",
        "print(dogface.shape[0])\n",
        "print(dogface.shape[1])\n",
        "plt.imshow(fresh_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "bCVZFlDhebfW"
      },
      "source": [
        "## Matrix slicing\n",
        "In OpenCV python style, as I have mentioned, images are numpy arrays. There are some superb array manipulation in numpy tutorials out there: this is a great introduction if you've not done it before [http://www.scipy-lectures.org/intro/numpy/numpy.html#indexing-and-slicing]. The getting and setting of regions above uses slicing, though, and I'd like to finish this notebook with a little more detail on what is going on there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "9LLhUPE7ebfX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "freshim2 = cv2.imread(\"noidea.jpg\")\n",
        "crop = freshim2[100:400, 130:300] \n",
        "plt.imshow(crop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "3pURgAtbebfZ"
      },
      "source": [
        "The key thing to note here is that the slicing works like\n",
        "```\n",
        "[top_y:bottom_y, left_x:right_x]\n",
        "```\n",
        "This can also be thought of as \n",
        "```\n",
        "[y:y+height, x:x+width]\n",
        "```\n",
        "\n",
        "You can also use slicing to separate out channels.  In this case you want \n",
        "```\n",
        "[y:y+height, x:x+width, channel]\n",
        "```\n",
        "where channel represents the colour you're interested in - this could be 0 = blue, 1 = green or 2=red if you're dealing with a default OpenCV image, but if you've got an image that has been converted it could be something else. Here's an example that converts to HSV then selects the S (Saturation) channel of the same crop above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "9cSa7WDHebfZ"
      },
      "outputs": [],
      "source": [
        "hsvim=cv2.cvtColor(freshim2,cv2.COLOR_BGR2HSV)\n",
        "bcrop =hsvim[100:400, 100:300, 1]\n",
        "plt.imshow(bcrop, cmap=\"gray\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1-Fundamentals.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
